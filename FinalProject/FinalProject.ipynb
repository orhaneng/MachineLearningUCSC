{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X  Y month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  area\n0  7  5   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0   0.0\n1  7  4   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0   0.0\n2  7  4   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0   0.0\n3  8  6   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2   0.0\n4  8  6   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0   0.0\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('/Users/omerorhan/Desktop/UCSC/MachineLearning/Assignments/venv/notebookfiles'\n",
    "                      '/FinalProject/forestfires.csv')\n",
    "print(dataset.head())\n",
    "\n",
    "#print(dataset.describe(include='all'))\n",
    "dataset.month.replace(('jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec'),(1,2,3,4,5,6,7,8,9,10,11,12), inplace=True)\n",
    "dataset.day.replace(('mon','tue','wed','thu','fri','sat','sun'),(1,2,3,4,5,6,7), inplace =True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of the Dataset:               X         Y     month       day      FFMC       DMC        DC  \\\nX      1.000000  0.539548 -0.065003 -0.024922 -0.021039 -0.048384 -0.085916   \nY      0.539548  1.000000 -0.066292 -0.005453 -0.046308  0.007782 -0.101178   \nmonth -0.065003 -0.066292  1.000000 -0.050837  0.291477  0.466645  0.868698   \nday   -0.024922 -0.005453 -0.050837  1.000000 -0.041068  0.062870  0.000105   \nFFMC  -0.021039 -0.046308  0.291477 -0.041068  1.000000  0.382619  0.330512   \nDMC   -0.048384  0.007782  0.466645  0.062870  0.382619  1.000000  0.682192   \nDC    -0.085916 -0.101178  0.868698  0.000105  0.330512  0.682192  1.000000   \nISI    0.006210 -0.024488  0.186597  0.032909  0.531805  0.305128  0.229154   \ntemp  -0.051258 -0.024103  0.368842  0.052190  0.431532  0.469594  0.496208   \nRH     0.085223  0.062221 -0.095280  0.092151 -0.300995  0.073795 -0.039192   \nwind   0.018798 -0.020341 -0.086368  0.032478 -0.028485 -0.105342 -0.203466   \nrain   0.065387  0.033234  0.013438 -0.048340  0.056702  0.074790  0.035861   \narea   0.063385  0.044873  0.056496  0.023226  0.040122  0.072994  0.049383   \n\n            ISI      temp        RH      wind      rain      area  \nX      0.006210 -0.051258  0.085223  0.018798  0.065387  0.063385  \nY     -0.024488 -0.024103  0.062221 -0.020341  0.033234  0.044873  \nmonth  0.186597  0.368842 -0.095280 -0.086368  0.013438  0.056496  \nday    0.032909  0.052190  0.092151  0.032478 -0.048340  0.023226  \nFFMC   0.531805  0.431532 -0.300995 -0.028485  0.056702  0.040122  \nDMC    0.305128  0.469594  0.073795 -0.105342  0.074790  0.072994  \nDC     0.229154  0.496208 -0.039192 -0.203466  0.035861  0.049383  \nISI    1.000000  0.394287 -0.132517  0.106826  0.067668  0.008258  \ntemp   0.394287  1.000000 -0.527390 -0.227116  0.069491  0.097844  \nRH    -0.132517 -0.527390  1.000000  0.069410  0.099751 -0.075519  \nwind   0.106826 -0.227116  0.069410  1.000000  0.061119  0.012317  \nrain   0.067668  0.069491  0.099751  0.061119  1.000000 -0.007366  \narea   0.008258  0.097844 -0.075519  0.012317 -0.007366  1.000000  \n"
     ]
    }
   ],
   "source": [
    "corr = dataset.corr(method='pearson')\n",
    "print(\"Correlation of the Dataset:\",corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-dbe3411d0fcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mLreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mLreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplained_variance_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "data = dataset.values\n",
    "\n",
    "X = data[:, 0:12]\n",
    "Y = data[:, 12]\n",
    "print(\"Linear Regression\")\n",
    "Lreg = LinearRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "Lreg.fit(X_train, Y_train)\n",
    "prediction = Lreg.predict(X)\n",
    "score = explained_variance_score(Y, prediction)\n",
    "mae = mean_absolute_error(prediction, Y)\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(prediction, Y))\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(\"coefficent\")\n",
    "print(Lreg.coef_)\n",
    "\"\"\"\n",
    "Explained variance regression score function\n",
    "http://www.enlistq.com/top-5-metrics-evaluating-regression-models/\n",
    "Explained Variance Score (EVS)\n",
    "As the name implies, EVS is a metric for calculating the ratio between variance of error and variance of true values. Alternatively, this score measures how well our model can explain variations in our dataset. \n",
    "Mathematically, it can be calculated using this formula:\n",
    "where y is the true value and \\hat{y}  is the predicted value.\n",
    "\n",
    "As evident by the formula, highest value your model can achieve is 1.0.\n",
    "\n",
    "Mean Absolute Error (MAE)\n",
    "MAE is a very widely used metric to evaluate regression models and a very simple one to understand as well.\n",
    "The metric is a measure of, on average, how much our predicted value can deviate from the the real value.\n",
    "The higher the metric, the higher the deviation from true value.\n",
    "It can be calculated by taking absolute values of the error (y-\\hat{y}) and then taking an average. \n",
    "Here is the formula:\n",
    "\n",
    "\n",
    "\n",
    "Here is how you can calculate it in scikit-learn:\n",
    "\n",
    "1\n",
    "2\n",
    "3\n",
    ">>> from sklearn.metrics import mean_absolute_error\n",
    ">>> mean_absolute_error(y_data, y_pred)\n",
    "0.19999999999999993\n",
    "This means that each predicted value can deviate 0.199 units from the real value. Note that the mean absolute error is in the same units as the value we are trying to predict. It is not a ratio.\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "plt.scatter(X[:,0], Y,  color='black')\n",
    "plt.plot(X[:,0], prediction, color='blue', linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()\n",
    "'''\n",
    "print(\"Score:\", score)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.values\n",
    "\n",
    "X = data[:, 0:12]\n",
    "Y = data[:, 12]\n",
    "print(\"Linear Regression\")\n",
    "Lreg = LinearRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "Lreg.fit(X_train, Y_train)\n",
    "prediction = Lreg.predict(X)\n",
    "score = explained_variance_score(Y, prediction)\n",
    "mae = mean_absolute_error(prediction, Y)\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(prediction, Y))\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(\"coefficent\")\n",
    "print(Lreg.coef_)\n",
    "\"\"\"\n",
    "Explained variance regression score function\n",
    "http://www.enlistq.com/top-5-metrics-evaluating-regression-models/\n",
    "Explained Variance Score (EVS)\n",
    "As the name implies, EVS is a metric for calculating the ratio between variance of error and variance of true values. Alternatively, this score measures how well our model can explain variations in our dataset. \n",
    "Mathematically, it can be calculated using this formula:\n",
    "where y is the true value and \\hat{y}  is the predicted value.\n",
    "\n",
    "As evident by the formula, highest value your model can achieve is 1.0.\n",
    "\n",
    "Mean Absolute Error (MAE)\n",
    "MAE is a very widely used metric to evaluate regression models and a very simple one to understand as well.\n",
    "The metric is a measure of, on average, how much our predicted value can deviate from the the real value.\n",
    "The higher the metric, the higher the deviation from true value.\n",
    "It can be calculated by taking absolute values of the error (y-\\hat{y}) and then taking an average. \n",
    "Here is the formula:\n",
    "\n",
    "\n",
    "\n",
    "Here is how you can calculate it in scikit-learn:\n",
    "\n",
    "1\n",
    "2\n",
    "3\n",
    ">>> from sklearn.metrics import mean_absolute_error\n",
    ">>> mean_absolute_error(y_data, y_pred)\n",
    "0.19999999999999993\n",
    "This means that each predicted value can deviate 0.199 units from the real value. Note that the mean absolute error is in the same units as the value we are trying to predict. It is not a ratio.\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "plt.scatter(X[:,0], Y,  color='black')\n",
    "plt.plot(X[:,0], prediction, color='blue', linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()\n",
    "'''\n",
    "print(\"Score:\", score)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor\nScore: 0.8296131579789745\nMean Absolute Error: 7.86771360412637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tf-cpu/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Regressor')\n",
    "#supervised learning algorithm\n",
    "\"\"\"\n",
    "https://towardsdatascience.com/the-random-forest-algorithm-d457d499ffcd\n",
    "https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/\n",
    "To say it in simple words: Random\n",
    " forest builds multiple decision trees and merges them together to get a more accurate and stable \n",
    " prediction.\n",
    " One big advantage of random forest is, that it can be used for both classification and regression problems,\n",
    "https://www.datacamp.com/community/tutorials/random-forests-classifier-python\n",
    "\"\"\"\n",
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X,Y)\n",
    "prediction_rfreg = rfreg.predict(X)\n",
    "score = explained_variance_score(Y, prediction_rfreg)\n",
    "mae = mean_absolute_error(prediction_rfreg, Y)\n",
    "\n",
    "print(\"Score:\", score)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is a difficult regression task, where the aim is to predict the burned area of forest fires, \n",
    "in the northeast region of Portugal, by using meteorological and other data\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/forest+fires\n",
    "\n",
    "Structure of the FWI System\n",
    "The diagram below illustrates the components of the FWI System. Calculation of the components is based \n",
    "on consecutive daily observations of temperature, relative humidity, wind speed, and 24-hour rainfall. \n",
    "DMC, duff moisture code; \n",
    "FFMC, fine fuel moisture code\n",
    "DC, drought code;\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
